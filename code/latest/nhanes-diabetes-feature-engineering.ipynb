{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datasets import load_dataset\nfrom typing import List, Tuple, Any, Dict, Optional","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-02T20:35:01.457182Z","iopub.execute_input":"2025-12-02T20:35:01.457482Z","iopub.status.idle":"2025-12-02T20:35:13.227493Z","shell.execute_reply.started":"2025-12-02T20:35:01.457459Z","shell.execute_reply":"2025-12-02T20:35:13.226661Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"dataset = load_dataset(\"rtweera/nhanes-dataset-selected-raw-attributes-v3\", split=\"train\")\ndf = dataset.to_pandas()\ndf.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T20:35:16.047540Z","iopub.execute_input":"2025-12-02T20:35:16.048730Z","iopub.status.idle":"2025-12-02T20:35:21.389287Z","shell.execute_reply.started":"2025-12-02T20:35:16.048696Z","shell.execute_reply":"2025-12-02T20:35:21.388549Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/31.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4087b34a9fc2467eae27fb37976bb402"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"nhanes-selected-attributes-raw-v3.parque(â€¦):   0%|          | 0.00/11.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07d921edbe9c46969f2b58013ca2981d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/101316 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ed18ac190c84c708b99460022390707"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(101316, 375)"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def str_to_list(string: str) -> list:\n    return [x.strip() for x in string.strip().split(\"\\n\")]\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T20:35:25.158005Z","iopub.execute_input":"2025-12-02T20:35:25.158283Z","iopub.status.idle":"2025-12-02T20:35:25.163068Z","shell.execute_reply.started":"2025-12-02T20:35:25.158262Z","shell.execute_reply":"2025-12-02T20:35:25.162287Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"nominal_attr_groups = {\n    \"CHOL_LIFESTYLE_CHANGES\": str_to_list(\n        \"\"\"\n        BPD110A__questionnaire\n        BPD110B__questionnaire\n        BPD110C__questionnaire\n        BPD120__questionnaire\n        BPD130__questionnaire\n        BPD140__questionnaire\n        \"\"\"\n    ),\n    \"HTN_LIFESTYLE_CHANGES_TOLD\": str_to_list(\n        \"\"\"\n        BPQ040B__questionnaire\n        BPQ040C__questionnaire\n        BPQ040D__questionnaire\n        BPQ040E__questionnaire\n        BPQ040F__questionnaire\n        BPQ043A__questionnaire\n        BPQ043B__questionnaire\n        BPQ043C__questionnaire\n        BPQ043D__questionnaire\n        \"\"\"\n    ),\n    \"HTN_LIFESTYLE_CHANGES_NOW\": str_to_list(\n        \"\"\"\n        BPQ050B__questionnaire\n        BPQ050C__questionnaire\n        BPQ050D__questionnaire\n        BPQ050E__questionnaire\n        \"\"\"\n    ), \n    \"CHOL_LIFESTYLE_CHANGES_TOLD\": str_to_list(\n        \"\"\"\n        BPQ090A__questionnaire\n        BPQ090B__questionnaire\n        BPQ090C__questionnaire\n        \"\"\"\n    ),\n    \"CHOL_LIFESTYLE_CHANGES_NOW\": str_to_list(\n        \"\"\"\n        BPQ100A__questionnaire\n        BPQ100B__questionnaire\n        BPQ100C__questionnaire\n        \"\"\"\n    ),\n    \"LEG_PAIN\": str_to_list(\n        \"\"\"\n        DIQ140__questionnaire\n        DIQ150__questionnaire\n        \"\"\"\n    ),\n    \"PREDIAB_RISK\": str_to_list(\n        \"\"\"\n        DIQ160__questionnaire\n        DIQ170__questionnaire\n        DIQ172__questionnaire\n        \"\"\"\n    ), \n    \"PREDIAB_RISK_REASON\": str_to_list(\n        \"\"\"\n        DIQ175A__questionnaire\n        DIQ175B__questionnaire\n        DIQ175C__questionnaire\n        DIQ175D__questionnaire\n        DIQ175E__questionnaire\n        DIQ175F__questionnaire\n        DIQ175G__questionnaire\n        DIQ175H__questionnaire\n        DIQ175I__questionnaire\n        DIQ175J__questionnaire\n        DIQ175K__questionnaire\n        DIQ175L__questionnaire\n        DIQ175M__questionnaire\n        DIQ175N__questionnaire\n        DIQ175O__questionnaire\n        DIQ175P__questionnaire\n        DIQ175Q__questionnaire\n        DIQ175R__questionnaire\n        DIQ175S__questionnaire\n        DIQ175T__questionnaire\n        DIQ175U__questionnaire\n        DIQ175V__questionnaire\n        DIQ175W__questionnaire\n        DIQ175X__questionnaire\n        \"\"\"\n    ),\n    \"DIAB_FAMILY_HISTORY_INDEX\": str_to_list(\n        \"\"\"\n        HAC5A1__questionnaire\n        HAC5A10__questionnaire\n        HAC5A11__questionnaire\n        HAC5A12__questionnaire\n        HAC5A2__questionnaire\n        HAC5A3__questionnaire\n        HAC5A4__questionnaire\n        HAC5A5__questionnaire\n        HAC5A6__questionnaire\n        HAC5A7__questionnaire\n        HAC5A8__questionnaire\n        HAC5A9__questionnaire\n        \"\"\"\n    ),\n    \"HBP_LIFESTYLE_CHANGES_TOLD\": str_to_list(\n        \"\"\"\n        HAE4B__questionnaire\n        HAE4C__questionnaire\n        HAE4D1__questionnaire\n        HAE4D2__questionnaire\n        HAE4D3__questionnaire\n        HAE4D4__questionnaire\n        HAE4D5__questionnaire\n        HAE4D6__questionnaire\n        \"\"\"\n    ),\n    \"HBP_LIFESTYLE_CHANGES_NOW\": str_to_list(\n        \"\"\"\n        HAE5B__questionnaire\n        HAE5C__questionnaire\n        HAE5D1__questionnaire\n        HAE5D2__questionnaire\n        HAE5D3__questionnaire\n        HAE5D4__questionnaire\n        HAE5D5__questionnaire\n        HAE5D6__questionnaire\n        \"\"\"\n    ),\n    \"HBC_LIFESTYLE_CHANGES_TOLD\": str_to_list(\n        \"\"\"\n        HAE8A__questionnaire\n        HAE8B__questionnaire\n        HAE8C__questionnaire\n        \"\"\"\n    ),\n    \"HBC_LIFESTYLE_CHANGES_NOW\": str_to_list(\n        \"\"\"\n        HAE9A__questionnaire\n        HAE9B__questionnaire\n        HAE9C__questionnaire\n        \"\"\"\n    ),\n    \"DIET_CHANGE_REASON\": str_to_list(\n        \"\"\"\n        HAM15A__questionnaire\n        HAM15B__questionnaire\n        HAM15C__questionnaire\n        HAM15D__questionnaire\n        HAM15Y__questionnaire\n        \"\"\"\n    ), \n    \"CURRENT_TOBACCO_USE\": str_to_list(\n        \"\"\"\n        HAR16__questionnaire\n        HAR24__questionnaire\n        HAR27__questionnaire\n        HAR3__questionnaire\n        \"\"\"\n    ),\n    \n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T20:35:37.219832Z","iopub.execute_input":"2025-12-02T20:35:37.220401Z","iopub.status.idle":"2025-12-02T20:35:37.226910Z","shell.execute_reply.started":"2025-12-02T20:35:37.220377Z","shell.execute_reply":"2025-12-02T20:35:37.225954Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"nominal_attr_groups","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T20:35:40.820229Z","iopub.execute_input":"2025-12-02T20:35:40.821041Z","iopub.status.idle":"2025-12-02T20:35:40.826904Z","shell.execute_reply.started":"2025-12-02T20:35:40.821008Z","shell.execute_reply":"2025-12-02T20:35:40.826322Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'CHOL_LIFESTYLE_CHANGES': ['BPD110A__questionnaire',\n  'BPD110B__questionnaire',\n  'BPD110C__questionnaire',\n  'BPD120__questionnaire',\n  'BPD130__questionnaire',\n  'BPD140__questionnaire'],\n 'HTN_LIFESTYLE_CHANGES_TOLD': ['BPQ040B__questionnaire',\n  'BPQ040C__questionnaire',\n  'BPQ040D__questionnaire',\n  'BPQ040E__questionnaire',\n  'BPQ040F__questionnaire',\n  'BPQ043A__questionnaire',\n  'BPQ043B__questionnaire',\n  'BPQ043C__questionnaire',\n  'BPQ043D__questionnaire'],\n 'HTN_LIFESTYLE_CHANGES_NOW': ['BPQ050B__questionnaire',\n  'BPQ050C__questionnaire',\n  'BPQ050D__questionnaire',\n  'BPQ050E__questionnaire'],\n 'CHOL_LIFESTYLE_CHANGES_TOLD': ['BPQ090A__questionnaire',\n  'BPQ090B__questionnaire',\n  'BPQ090C__questionnaire'],\n 'CHOL_LIFESTYLE_CHANGES_NOW': ['BPQ100A__questionnaire',\n  'BPQ100B__questionnaire',\n  'BPQ100C__questionnaire'],\n 'LEG_PAIN': ['DIQ140__questionnaire', 'DIQ150__questionnaire'],\n 'PREDIAB_RISK': ['DIQ160__questionnaire',\n  'DIQ170__questionnaire',\n  'DIQ172__questionnaire'],\n 'PREDIAB_RISK_REASON': ['DIQ175A__questionnaire',\n  'DIQ175B__questionnaire',\n  'DIQ175C__questionnaire',\n  'DIQ175D__questionnaire',\n  'DIQ175E__questionnaire',\n  'DIQ175F__questionnaire',\n  'DIQ175G__questionnaire',\n  'DIQ175H__questionnaire',\n  'DIQ175I__questionnaire',\n  'DIQ175J__questionnaire',\n  'DIQ175K__questionnaire',\n  'DIQ175L__questionnaire',\n  'DIQ175M__questionnaire',\n  'DIQ175N__questionnaire',\n  'DIQ175O__questionnaire',\n  'DIQ175P__questionnaire',\n  'DIQ175Q__questionnaire',\n  'DIQ175R__questionnaire',\n  'DIQ175S__questionnaire',\n  'DIQ175T__questionnaire',\n  'DIQ175U__questionnaire',\n  'DIQ175V__questionnaire',\n  'DIQ175W__questionnaire',\n  'DIQ175X__questionnaire'],\n 'DIAB_FAMILY_HISTORY_INDEX': ['HAC5A1__questionnaire',\n  'HAC5A10__questionnaire',\n  'HAC5A11__questionnaire',\n  'HAC5A12__questionnaire',\n  'HAC5A2__questionnaire',\n  'HAC5A3__questionnaire',\n  'HAC5A4__questionnaire',\n  'HAC5A5__questionnaire',\n  'HAC5A6__questionnaire',\n  'HAC5A7__questionnaire',\n  'HAC5A8__questionnaire',\n  'HAC5A9__questionnaire'],\n 'HBP_LIFESTYLE_CHANGES_TOLD': ['HAE4B__questionnaire',\n  'HAE4C__questionnaire',\n  'HAE4D1__questionnaire',\n  'HAE4D2__questionnaire',\n  'HAE4D3__questionnaire',\n  'HAE4D4__questionnaire',\n  'HAE4D5__questionnaire',\n  'HAE4D6__questionnaire'],\n 'HBP_LIFESTYLE_CHANGES_NOW': ['HAE5B__questionnaire',\n  'HAE5C__questionnaire',\n  'HAE5D1__questionnaire',\n  'HAE5D2__questionnaire',\n  'HAE5D3__questionnaire',\n  'HAE5D4__questionnaire',\n  'HAE5D5__questionnaire',\n  'HAE5D6__questionnaire'],\n 'HBC_LIFESTYLE_CHANGES_TOLD': ['HAE8A__questionnaire',\n  'HAE8B__questionnaire',\n  'HAE8C__questionnaire'],\n 'HBC_LIFESTYLE_CHANGES_NOW': ['HAE9A__questionnaire',\n  'HAE9B__questionnaire',\n  'HAE9C__questionnaire'],\n 'DIET_CHANGE_REASON': ['HAM15A__questionnaire',\n  'HAM15B__questionnaire',\n  'HAM15C__questionnaire',\n  'HAM15D__questionnaire',\n  'HAM15Y__questionnaire'],\n 'CURRENT_TOBACCO_USE': ['HAR16__questionnaire',\n  'HAR24__questionnaire',\n  'HAR27__questionnaire',\n  'HAR3__questionnaire']}"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def reduce_nominal_dimensions(\n    df: pd.DataFrame,\n    attr_groups: Dict[str, List[str]],\n    count_value: int = 1,\n    max_count: Optional[int] = None,\n    drop_original: bool = True\n) -> pd.DataFrame:\n    \"\"\"\n    Reduce dimensionality by combining nominal attributes into count columns.\n    \n    Parameters:\n    -----------\n    df : pd.DataFrame\n        Input dataframe\n    attr_groups : Dict[str, List[str]]\n        Dictionary mapping new column names to lists of original columns to combine\n    count_value : int, default=1\n        The value to count in the original columns (e.g., 1 means count occurrences of 1)\n    max_count : Optional[int], default=None\n        Maximum value to cap the count at. If None, no capping is applied\n    drop_original : bool, default=True\n        Whether to drop the original columns after creating new ones\n    \n    Returns:\n    --------\n    pd.DataFrame\n        DataFrame with new combined columns\n    \n    Examples:\n    ---------\n    >>> # Count occurrences of 1, cap at 5, drop original columns\n    >>> df_reduced = reduce_nominal_dimensions(\n    ...     df, \n    ...     nominal_attr_groups, \n    ...     count_value=1, \n    ...     max_count=5, \n    ...     drop_original=True\n    ... )\n    \n    >>> # Count occurrences of 2, no cap, keep original columns\n    >>> df_reduced = reduce_nominal_dimensions(\n    ...     df, \n    ...     nominal_attr_groups, \n    ...     count_value=2, \n    ...     max_count=None, \n    ...     drop_original=False\n    ... )\n    \"\"\"\n    df_result = df.copy()\n    columns_to_drop = []\n    \n    for new_col_name, original_cols in attr_groups.items():\n        # Filter to only existing columns in the dataframe\n        existing_cols = [col for col in original_cols if col in df.columns]\n        \n        if len(existing_cols) != len(original_cols):\n            raise ValueError(\"Error: column length mismatch in nominal feature reduction\")\n        \n        # Count occurrences of the specified value across the columns\n        # Using .eq() to compare with count_value, then sum across columns\n        count_series = df[existing_cols].eq(count_value).sum(axis=1)\n        \n        # Apply max_count cap if specified\n        if max_count is not None:\n            count_series = count_series.clip(upper=max_count)\n        \n        # Add the new column\n        df_result[new_col_name] = count_series\n        \n        # Track columns to drop\n        if drop_original:\n            columns_to_drop.extend(existing_cols)\n    \n    # Drop original columns if requested\n    if drop_original:\n        columns_to_drop = list(set(columns_to_drop))  # Remove duplicates\n        df_result = df_result.drop(columns=columns_to_drop, errors='ignore')\n    \n    return df_result\n\n# EXAMPLE USAGE\n# Apply to your dataframe\n# df_reduced = reduce_nominal_dimensions(\n#     df=your_dataframe,\n#     attr_groups=nominal_attr_groups,\n#     count_value=1,        # Count occurrences of 1 (that is 'yes' values)\n#     max_count=5,          # Cap at 5 (or None for no cap)\n#     drop_original=True    # Drop original columns\n# )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T20:35:55.011813Z","iopub.execute_input":"2025-12-02T20:35:55.012551Z","iopub.status.idle":"2025-12-02T20:35:55.020203Z","shell.execute_reply.started":"2025-12-02T20:35:55.012501Z","shell.execute_reply":"2025-12-02T20:35:55.019310Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def reduce_dietary_features(\n    df: pd.DataFrame,\n    drop_original: bool = True\n) -> pd.DataFrame:\n    \"\"\"\n    Reduce specific dietary intake frequencies into clinically relevant \n    aggregated features for diabetes prediction.\n    \n    Groups foods by their metabolic impact and nutritional characteristics\n    relevant to diabetes risk and management.\n    \n    Parameters:\n    -----------\n    df : pd.DataFrame\n        Input dataframe with detailed food frequency columns\n    drop_original : bool\n        Whether to drop the original detailed columns\n    \n    Returns:\n    --------\n    pd.DataFrame\n        DataFrame with aggregated dietary features\n    \"\"\"\n    df_result = df.copy()\n    \n    # Define food groupings based on metabolic/diabetes relevance\n    food_groups = {\n        # High glycemic load carbohydrates\n        'REFINED_CARBS_FREQ': [\n            'HAN5GS__questionnaire',\n            'HAN6AS__questionnaire',\n            'HAN4DS__questionnaire',\n            'HAN5KS__questionnaire',\n            'HAN5JS__questionnaire',\n            'HAN2BS__questionnaire'\n        ],\n        \n        # Whole grains and complex carbs (better for diabetes)\n        'WHOLE_GRAINS_FREQ': [\n            'HAN5HS__questionnaire',\n            'HAN5IS__questionnaire'\n        ],\n        \n        # Added sugars and sweetened beverages (high diabetes risk)\n        'ADDED_SUGARS_FREQ': [\n            'HAN6ES__questionnaire',\n            'HAN6CS__questionnaire',\n            'HAN6BS__questionnaire',\n            'HAN1AS__questionnaire',\n            'HAN1FS__questionnaire'\n        ],\n        \n        # Fruits and natural fruit sources (fiber + natural sugars)\n        'FRUIT_INTAKE_FREQ': [\n            'HAN3AS__questionnaire',\n            'HAN3BS__questionnaire',\n            'HAN3DS__questionnaire',\n            'HAN3ES__questionnaire',\n            'HAN3FS__questionnaire',\n            'HAN4ES__questionnaire'  # High in fiber, better GI\n        ],\n        \n        # Dairy products (protein, calcium, fat content varies)\n        'DAIRY_FREQ': [\n            'HAN1BS__questionnaire',\n            'HAN1GS__questionnaire',\n            'HAN1IS__questionnaire',\n            'HAN1HS__questionnaire'  # Cheese-heavy\n        ],\n        \n        # Alcohol consumption (affects blood sugar regulation)\n        'ALCOHOL_FREQ': [\n            'HAN6HS__questionnaire',\n            'HAN6IS__questionnaire',\n            'HAN6JS__questionnaire'\n        ],\n        \n        # Saturated fats\n        'SATURATED_FAT_FREQ': [\n            'HAN7BS__questionnaire'\n        ],\n        \n        # Diet/low-calorie beverages\n        'DIET_BEVERAGES_FREQ': [\n            'HAN6DS__questionnaire'\n        ]\n    }\n    \n    columns_to_drop = []\n    \n    # Create aggregated features\n    for new_feature, food_items in food_groups.items():\n        existing_cols = [col for col in food_items if col in df.columns]\n        \n        if existing_cols:\n            # Sum frequencies across all items in the group\n            # NaN values are ignored in sum (treated as 0)\n            df_result[new_feature] = df[existing_cols].sum(axis=1, min_count=1)\n            columns_to_drop.extend(existing_cols)\n    \n    # Create derived ratios and composite features\n    # These provide more nuanced dietary pattern information\n    \n    # Ratio of refined to whole grains (higher = worse for diabetes)\n    if 'REFINED_CARBS_FREQ' in df_result.columns and 'WHOLE_GRAINS_FREQ' in df_result.columns:\n        df_result['REFINED_TO_WHOLE_GRAIN_RATIO'] = (\n            df_result['REFINED_CARBS_FREQ'] / \n            (df_result['WHOLE_GRAINS_FREQ'] + 1)  # Add 1 to avoid division by zero\n        )\n    \n    # Ratio of added sugars to fruit intake\n    if 'ADDED_SUGARS_FREQ' in df_result.columns and 'FRUIT_INTAKE_FREQ' in df_result.columns:\n        df_result['SUGAR_TO_FRUIT_RATIO'] = (\n            df_result['ADDED_SUGARS_FREQ'] / \n            (df_result['FRUIT_INTAKE_FREQ'] + 1)\n        )\n    \n    # Total unhealthy dietary pattern score (sum of risk factors)\n    unhealthy_components = ['REFINED_CARBS_FREQ', 'ADDED_SUGARS_FREQ', \n                           'SATURATED_FAT_FREQ', 'ALCOHOL_FREQ']\n    existing_unhealthy = [col for col in unhealthy_components if col in df_result.columns]\n    if existing_unhealthy:\n        df_result['UNHEALTHY_DIET_SCORE'] = df_result[existing_unhealthy].sum(axis=1, min_count=1)\n    \n    # Total healthy dietary pattern score\n    healthy_components = ['WHOLE_GRAINS_FREQ', 'FRUIT_INTAKE_FREQ', 'VEGETABLE_DISHES_FREQ']\n    existing_healthy = [col for col in healthy_components if col in df_result.columns]\n    if existing_healthy:\n        df_result['HEALTHY_DIET_SCORE'] = df_result[existing_healthy].sum(axis=1, min_count=1)\n    \n    # Overall diet quality ratio\n    if 'HEALTHY_DIET_SCORE' in df_result.columns and 'UNHEALTHY_DIET_SCORE' in df_result.columns:\n        df_result['DIET_QUALITY_RATIO'] = (\n            df_result['HEALTHY_DIET_SCORE'] / \n            (df_result['UNHEALTHY_DIET_SCORE'] + 1)\n        )\n    \n    # Drop original columns if requested\n    if drop_original:\n        columns_to_drop = list(set(columns_to_drop))\n        df_result = df_result.drop(columns=columns_to_drop, errors='ignore')\n    \n    return df_result\n\n# EXAMPLE USAGE\n# # Reduce dietary features\n# df_reduced = reduce_dietary_features(df_sample, drop_original=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T20:36:04.347314Z","iopub.execute_input":"2025-12-02T20:36:04.348105Z","iopub.status.idle":"2025-12-02T20:36:04.359620Z","shell.execute_reply.started":"2025-12-02T20:36:04.348075Z","shell.execute_reply":"2025-12-02T20:36:04.358773Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def reduce_activity_features(\n    df: pd.DataFrame,\n    drop_original: bool = True,\n    vigorous_weight: int = 2,\n    moderate_weight: int = 1\n) -> pd.DataFrame:\n    \"\"\"\n    Combines vigorous and moderate physical activity features into a single,\n    weighted total activity time feature.\n\n    Vigorous activity is weighted more heavily, reflecting its higher\n    MET (Metabolic Equivalent of Task) value.\n\n    Parameters:\n    -----------\n    df : pd.DataFrame\n        Input dataframe containing the physical activity columns.\n    vigorous_col : str\n        Name of the column representing vigorous activity time.\n    moderate_col : str\n        Name of the column representing moderate activity time.\n    vigorous_weight : int\n        Weight/multiplier for the vigorous activity column (default is 2).\n    moderate_weight : int\n        Weight/multiplier for the moderate activity column (default is 1).\n    drop_original : bool\n        Whether to drop the original detailed columns (PAQ650 and PAQ665).\n\n    Returns:\n    --------\n    pd.DataFrame\n        DataFrame with the new aggregated 'TOTAL_WEEKLY_ACTIVITY_TIME' feature.\n    \"\"\"\n    df_result = df.copy()\n\n    vigorous_col: str = 'PAQ650__questionnaire'\n    moderate_col: str = 'PAQ665__questionnaire'\n    \n    \n    activity_cols = [vigorous_col, moderate_col,\n                     \"PAD615__questionnaire\",\n                     \"PAD630__questionnaire\",\n                     \"PAD645__questionnaire\",\n                     \"PAD660__questionnaire\",\n                     \"PAD675__questionnaire\",\n                    ]\n    \n    # Check if required columns exist\n    if not all(col in df.columns for col in activity_cols):\n        missing_cols = [col for col in activity_cols if col not in df.columns]\n        raise ValueError(f\"Warning: Missing columns for activity aggregation: {missing_cols}\")\n\n    # 1. Multiply the vigorous activity column by its weight (e.g., 2)\n    #    The `fillna(0)` ensures that NaN values don't propagate and are treated\n    #    as 0 for the multiplication/sum, which is appropriate for time measures.\n    df_result[f'{vigorous_col}_weighted'] = (\n        df[vigorous_col].fillna(0) * vigorous_weight\n    )\n\n    # 2. Multiply the moderate activity column by its weight (e.g., 1)\n    df_result[f'{moderate_col}_weighted'] = (\n        df[moderate_col].fillna(0) * moderate_weight\n    )\n\n    # 3. Sum the weighted columns to get the total activity time\n    df_result['TOTAL_WEEKLY_ACTIVITY_TIME'] = (\n        df_result[f'{vigorous_col}_weighted'] + \n        df_result[f'{moderate_col}_weighted']\n    )\n\n    # 4. Drop temporary weighted columns\n    df_result = df_result.drop(\n        columns=[f'{vigorous_col}_weighted', f'{moderate_col}_weighted'],\n        errors='raise'\n    )\n\n    # Define the activity columns and their corresponding weights\n    activity_groups = {\n        # Vigorous activities (Weight = 2)\n        'VIGOROUS': [\n            'PAD615__questionnaire',  # Vigorous at work\n            'PAD660__questionnaire'   # Vigorous recreation\n        ],\n        # Moderate activities (Weight = 1)\n        'MODERATE': [\n            'PAD630__questionnaire',  # Moderate at work\n            'PAD645__questionnaire',  # Walking/bicycling for travel\n            'PAD675__questionnaire'   # Moderate recreation\n        ]\n    }\n    \n    # Initialize the new score column to zero\n    df_result[\"TOTAL_DAILY_ACTIVITY_SCORE\"] = 0.0\n\n    columns_to_sum = []\n    \n    # Process Vigorous Activities\n    for col in activity_groups['VIGOROUS']:\n        if col in df.columns:\n            # Multiply time by the vigorous weight (e.g., 2)\n            # .fillna(0) ensures NaNs are treated as 0 for the calculation\n            df_result['TOTAL_DAILY_ACTIVITY_SCORE'] += df[col].fillna(0) * vigorous_weight\n            columns_to_sum.append(col)\n\n    # Process Moderate Activities\n    for col in activity_groups['MODERATE']:\n        if col in df.columns:\n            # Multiply time by the moderate weight (e.g., 1)\n            df_result['TOTAL_DAILY_ACTIVITY_SCORE'] += df[col].fillna(0) * moderate_weight\n            columns_to_sum.append(col)\n\n    # Note on handling NaNs:\n    # We used .fillna(0) before the calculation. This treats missing activity data\n    # as 'zero minutes of activity' for the *score calculation*.\n\n    # Now, check if all original columns were missing for a row.\n    # If *all* original columns are NaN for a person, the aggregated score\n    # should ideally be NaN to reflect a lack of data, not zero activity.\n    \n    # Identify rows where ALL five original columns were NaN\n    all_original_cols = activity_groups['VIGOROUS'] + activity_groups['MODERATE']\n    \n    # Use .all(axis=1) on the boolean mask to find rows where all are True (i.e., all NaNs)\n    all_nan_mask = df[all_original_cols].isna().all(axis=1)\n    \n    # Apply NaN to the final score for those rows\n    df_result.loc[all_nan_mask, 'TOTAL_DAILY_ACTIVITY_SCORE'] = float('nan')\n\n    activity_cols.extend(columns_to_sum)\n    # 5. Drop original columns if requested\n    if drop_original:\n        df_result = df_result.drop(columns=activity_cols, errors='raise')\n\n    return df_result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T20:42:57.048125Z","iopub.execute_input":"2025-12-02T20:42:57.048735Z","iopub.status.idle":"2025-12-02T20:42:57.059307Z","shell.execute_reply.started":"2025-12-02T20:42:57.048703Z","shell.execute_reply":"2025-12-02T20:42:57.058563Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def preprocess_pipeline(df: pd.DataFrame)->pd.DataFrame:\n    df = reduce_nominal_dimensions(\n        df=df,\n        attr_groups=nominal_attr_groups,\n        count_value=1,        # Count occurrences of 1 (that is 'yes' values)\n        max_count=5,          # Cap at 5 (or None for no cap)\n        drop_original=True    # Drop original columns\n    )\n    df = reduce_dietary_features(\n        df=df,\n        drop_original=True\n    )\n    df = reduce_activity_features(\n        df=df,\n        drop_original=True\n    )\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T20:42:59.313236Z","iopub.execute_input":"2025-12-02T20:42:59.313862Z","iopub.status.idle":"2025-12-02T20:42:59.318849Z","shell.execute_reply.started":"2025-12-02T20:42:59.313834Z","shell.execute_reply":"2025-12-02T20:42:59.317949Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"reduced_df = preprocess_pipeline(df)\nreduced_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T20:43:00.796880Z","iopub.execute_input":"2025-12-02T20:43:00.797616Z","iopub.status.idle":"2025-12-02T20:43:01.625686Z","shell.execute_reply.started":"2025-12-02T20:43:00.797557Z","shell.execute_reply":"2025-12-02T20:43:01.624988Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(101316, 273)"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"reduced_df.to_parquet(\"nhanes-feature-engineered.parquet\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T20:45:53.924542Z","iopub.execute_input":"2025-12-02T20:45:53.925370Z","iopub.status.idle":"2025-12-02T20:45:54.952389Z","shell.execute_reply.started":"2025-12-02T20:45:53.925345Z","shell.execute_reply":"2025-12-02T20:45:54.951735Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"reduced_df.to_csv(\"nhanes-feature-engineered.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T20:46:30.296359Z","iopub.execute_input":"2025-12-02T20:46:30.296986Z","iopub.status.idle":"2025-12-02T20:46:42.186210Z","shell.execute_reply.started":"2025-12-02T20:46:30.296963Z","shell.execute_reply":"2025-12-02T20:46:42.185487Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"\nmissing_count = reduced_df[\"REFINED_CARBS_FREQ\"].isna().sum()\n\n# 2. Calculate the total number of rows\ntotal_count = len(reduced_df[\"REFINED_CARBS_FREQ\"])\n\n(missing_count / total_count) * 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T20:56:41.635216Z","iopub.execute_input":"2025-12-02T20:56:41.635550Z","iopub.status.idle":"2025-12-02T20:56:41.642435Z","shell.execute_reply.started":"2025-12-02T20:56:41.635518Z","shell.execute_reply":"2025-12-02T20:56:41.641561Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"90.17035808756762"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}